

## 🟥 高レスポンスを求められるWebシステム
Webサイトを構築する際のルールとして、「**６秒ルール**」がある。  
これは、**６秒以内に表示を完了させないと、ユーザーを取り逃してしまう**というもので、また表示が遅くなることで、**再読み込みボタンが何度もクリックされ、サーバーの負荷が増す、という事態にもなり得る**。  
（最近では、モバイル端末での利用が増えたことによって「**３秒ルール**」というさらに厳しいルールも出てきている）

高レスポンスを実現するための手法には**２種類**あり、1つは、**Webサーバー単体の処理能力を高める「スケールアップ」**、もう一つは、**複数のWebサーバーに処理を分散したり、役割を分担して処理能力を高める「スケールアウト」** である。  

<br>

#### ● スケールアップ
**サーバーのCPUやメモリーなどを増強して、サーバー単体の処理能力を向上するとこで、大量のリクエストを捌けるようにすること**。  
ただし、**価格が２倍になったからといって、性能が２倍になるわけではなく**、そのサーバーが停止してしまえば、Webサイトはダウンすることになり、また**メンテナンス中もサービスを停止させる必要がある**。  

<br>

#### ● スケールアウト
**複数のサーバーをシステム化して、システム全体の性能を向上させる手法**。  
サーバー台数を2台に増やせが、性能も比例して向上できるため、**費用対効果が高くなる**。  
また複数のサーバーで処理を行うため、**そのうちの1台が停止しても他のサーバーで処理を継続できる**。  

大規模なWebサイトは、**1,000台を超えるサーバー**で１つのWebサイトを実現することも珍しくなく、**それを実現するための様々なWeb技術、仕組みが確立されている**。  

* **プロキシ**
* **キャッシュ**
* **ロードバランサー**
* **仮想化**

<br>
<br>
<br>

## 🟥 プロキシサーバーとは
プロキシは「**代理**」という意味で、**ブラウザの代わりにWebサーバーとのやりとりを行ったり**、またその逆のやりとりを行ったりするサーバー。  
ブラウザとサーバーの間を取り持つ、**中継地点**のような役割をすることで、アクセスの高速化が可能になる。  
プロキシサーバーを利用するには、必ず**ブラウザー側のネットワークもしくは、Webサーバー側のネットワークにつながるように接続して**、設置する必要がある。  

<br>

#### ● ブラウザー側に設置するメリット
主に3つ存在する。  
まず**Webアクセスをプロキシサーバーに集中させる（任せる）ことで、ネットワークを効率よく利用できること**。  
そして、Webサーバーとのやりとりをチェックさせて、**危険であると判断された通信を遮断する「ファイアーウォール」のような機能を果たすこと**。  
次に、**リソースをキャッシュとして保存しておくことで、次に同じリクエストが発生した際に、高速でレスポンスすることが可能になる**、ということである。  

このように、**事業所や家庭に設置して、ブラウザーの機能を補う方式を「フォワードプロキシ」と呼ぶ**。  

<br>

#### ● Webサーバー側に設置するメリット
この場合、**リクエストやレスポンスを一旦プロキシサーバーが受けて、オリジンサーバーやブラウザーに転送されるため、レスポンスの高速化を実現できる**。  
またブラウザーからのリクエストを一旦中継することで、**複数のWebサーバーに処理を分散させることが可能な上、Webサーバーの構成を外部から隠蔽するといった効果もある**。  

このように**Webサーバーにプロキシサーバーを置く方式を「リバースプロキシ」と呼ぶ**。  

<br>
<br>
<br>

## 🟥 ロードバランサー
スケーラビリティや耐障害性で優れている**スケールアウト**だが、クライアントからのリクエストを複数のサーバーに分散させるには、**そのための特別な仕組みが必要になる**。  
**それを可能にしているのが「ロードバランサー（負荷分散装置）」である**。  

<br>

「**ラウンドロビン方式**」では、単純に順番通りに各サーバーに割り振る。  

「**優先順位方式**」では、各オリジンサーバーに**優先順位**を設定し、それが高いサーバーから順にリクエストを割り振る。  
（優先順位が低いサーバーには、「**アクセス集中のため表示できません**」などのWebページを用意しておく）

「**重み付け方式**」では、高スペックなサーバーに対する重みを「**３**」、低スペックなサーバーに対する重みを「**１**」と設定することで、**アクセスを「３：１」の割合で高スペックなサーバーへ割り振ることができる**。  

<br>

より高度な負荷分散としては、**状況に応じて動的に動作する分散方式もあり**、  
「**最速応答時間方式**」では、応答が最も早いバックエンドサーバーを優先し、  
「**最小コネクション方式**」や「**最小トラフィック方式**」では、接続中のコネクション数やトラフィック量が最も少ないサーバーを優先して割り振る。  

<br>

複数の方式を組み合わせることも可能で、**ある一定量まではラウンドロビンで分散し、値を超えた場合のみ、優先順位方式で振り分ける**、なども可能。  
また「**コンテンツスイッチ方式**」では、**URLに「img」が含まれている場合はサーバー１、拡張子が「.php」の場合はサーバー２に割り振る**、などもできる。  

なお、これらの負荷分散を実現するには、**各オリジンサーバーをモニタリングする「ヘルスチェック機能」が必要で**、ロードバランサーの仕組みが複雑になるほど、**より高性能なロードバランサーが必要になる**。  

<br>
<br>
<br>

## 🟥 CDN
**世界中のネットワークにWebサーバーを分散配置して**、どこからアクセスしても迅速にコンテンツを受信できるようにしたネットワーク。  
本来なら縮めることのできない物理的な距離を、**CDN事業者と契約することで、その事業者が世界中に展開しているCDN網にコンテンツのコピーを配置することができる**。  
それにより、**物理的な距離を縮めることができるだけでなく、負荷分散にも貢献する**。

<br>
<br>
<br>

## 🟥 仮想化技術
これを使うと、**1台のコンピュータ上で複数のコンピュータを同時に起動することができる**。  
現実のコンピュータを「**物理マシン**」と呼ぶのに対し、仮想的なコンピュータを「**仮想マシン**」と呼ぶ。  
また仮想マシンを稼働させる物理マシン上のOSを「**ホストOS**」、仮想マシン上で動作しているOSを「**ゲストOS**」と呼んで区別する。  

<br>
<br>
<br>

## 🟥 SaaS
**クラウド上にあるソフトウェアをインターネットを経由して利用できるサービスのこと**。  
**Microsoft Office 365、Google Workspace、Dropbox、Evernote**など、すでに多くの SaaS が身近になっている。  
**インターネット環境さえあればどこからでもアクセス可能で、またアップデートやセットアップなども不要なため**、必要なときにすぐに利用できる。

<br>
<br>
<br>

## 🟥 Docker
**コンテナ型仮想化技術を用いて、構築したアプリケーションをデプロイ（展開）して実行したもの**。  

>  【**コンテナ型仮想化技術**】  
> アプリケーションの実行環境だけをエミュレートした仮想化技術。  
> ハードウェアを丸ごとエミュレートする「**ハイパーバイザー型**」と比べて、実行単位が小さくなる。  

<br>

Webアプリが組み込まれた「**Dockerイメージ**」をダウンロードするだけで、**面倒なOSやアプリケーションのインストールを行うことなく、Webサーバー環境を瞬時に用意できる**。  

<br>
<br>
<br>
